---
layout: default
title: Reading 10
id: reading10
---


# Reading Assignment 10: Text-to-Image Models

Generating images from a text description is one of the most impressive applications
right now. Below, you will find some exemplary papers released mainly by large
companies. These can be seen as case studies on how to set up "realistic" large-scale
models for complex generation tasks. Interesting questions to ask include:
- What's the basic idea/architecture?
- How big is the model?
- What data did they use?
- Did they use any "special tricks" and run ablation studies?

Even though most people do not have the resources available to recreate these
kinds of models, there is still a lot to learn on scalable, efficient deep
learning.

You are not expected to read all these papers in detail, but consider
"academic speed reading": Read the abstract, introduction, and conclusion. Check
the figures and tables for main results. Done! Alternatively, you could try reading
one or two papers in detail. Most of these will also have higher-level blog posts
accompanying the release, which you should find via internet search.

- [DALL-E](https://arxiv.org/pdf/2102.12092.pdf) by OpenAI, based on discrete
autoencoders and autoregressive priors.
- [GLIDE](https://arxiv.org/pdf/2112.10741.pdf) by OpenAI, based on diffusion
models (as are all the remaining systems on this list).
- [Latent Diffusion](https://arxiv.org/pdf/2112.10752.pdf), the only system on
this list not created by a major company, and the basis of the [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release)
system.
- [DALL-E 2](https://cdn.openai.com/papers/dall-e-2.pdf) by OpenAI.
- [Imagen](https://arxiv.org/pdf/2205.11487.pdf) by Google.
- [GigaGAN](https://mingukkang.github.io/GigaGAN/) as an example of a recent non-diffusion model.

## Bonus

- The OpenAI models use [CLIP](https://arxiv.org/pdf/2103.00020.pdf) as an important
component.
- Similar technology is also being explored for music: See
[MusicLM](https://google-research.github.io/seanet/musiclm/examples/) by Google
or [MusicGen](https://ai.honu.io/papers/musicgen/) by Meta.
